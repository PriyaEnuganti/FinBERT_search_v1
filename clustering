import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.cluster import KMeans
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import Normalizer
from sklearn.decomposition import TruncatedSVD
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Sample data
documents = pd.DataFrame({
    'title': ['Document 1', 'Document 2', 'Document 3', 'Document 4', 'Document 5'],
    'keywords': ['finance, stocks, trading', 'investment, bonds, portfolio', 'taxes, accounting, audit', 
                 'banking, loans, credit', 'budgeting, savings, retirement']
})

# Preprocess the data
vectorizer = CountVectorizer(stop_words='english')
X = vectorizer.fit_transform(documents['keywords'])

# Cluster the documents
n_clusters = 2
svd = TruncatedSVD(n_components=2)
normalizer = Normalizer(copy=False)
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
pipeline = make_pipeline(svd, normalizer, kmeans)
pipeline.fit(X)

# Reduce the dimensions of the data for visualization
tsne = TSNE(n_components=2, perplexity=10, learning_rate=200, random_state=42)
X_tsne = tsne.fit_transform(X.toarray())

# Plot the clusters
colors = ['red', 'blue', 'green', 'orange', 'purple', 'gray']
fig, ax = plt.subplots(figsize=(10, 8))
for i in range(n_clusters):
    mask = pipeline.named_steps['kmeans'].labels_ == i
    ax.scatter(X_tsne[mask, 0], X_tsne[mask, 1], c=colors[i], label=f'Cluster {i}')
ax.legend()
plt.show()
