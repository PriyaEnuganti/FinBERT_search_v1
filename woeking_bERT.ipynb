{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thGI0MFExUal",
        "outputId": "a68fda6c-732e-4c2d-ad72-5aee442c58ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load FinBERT pre-trained model and tokenizer\n",
        "model_name = \"ProsusAI/finbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Freeze all layers except the last one\n",
        "for name, param in model.named_parameters():\n",
        "    if 'classifier' not in name: # Only train the classifier layer\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEyiG3f-Fa0P",
        "outputId": "ff45deec-7ce7-42d5-8be3-283db8cd974f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jmpmGKmIqIRG"
      },
      "outputs": [],
      "source": [
        "# Define the two-tower model architecture\n",
        "class TwoTowerModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoTowerModel, self).__init__()\n",
        "        self.query_tower = model\n",
        "        self.doc_tower = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.cos_sim = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    def encode_query(self, query):\n",
        "        query_input_ids = self.tokenizer.encode(query, add_special_tokens=True, max_length=512, truncation=True)\n",
        "        query_input_ids = torch.tensor(query_input_ids).unsqueeze(0)\n",
        "        query_outputs = self.query_tower(query_input_ids)[0]\n",
        "        query_embedding = query_outputs.mean(axis=1)\n",
        "        return query_embedding\n",
        "    \n",
        "    def encode_document(self, document):\n",
        "        document_input_ids =self.tokenizer.encode(document, add_special_tokens=True, max_length=512, truncation=True)\n",
        "        document_input_ids = torch.tensor(document_input_ids).unsqueeze(0)\n",
        "        document_outputs = self.doc_tower(document_input_ids)[0]\n",
        "        document_embedding = document_outputs.mean(axis=1)\n",
        "        return document_embedding\n",
        "    def forward(self, query, document):\n",
        "        query_embedding = self.encode_query(query)\n",
        "        document_embedding = self.encode_document(document)\n",
        "        #dot_product = torch.mul(query_embedding, document_embedding).sum(dim=1)\n",
        "        #scores = self.fc(dot_product)\n",
        "        similarity_scores = self.cos_sim(query_embedding, document_embedding)\n",
        "        return similarity_scores\n",
        "\n",
        "''' def forward(self, query_input_ids, query_attention_mask, doc_input_ids, doc_attention_mask):\n",
        "        query_outputs = self.query_tower(input_ids=query_input_ids, attention_mask=query_attention_mask)\n",
        "        doc_outputs = self.doc_tower(input_ids=doc_input_ids, attention_mask=doc_attention_mask)\n",
        "        query_embeddings = query_outputs[1]\n",
        "        doc_embeddings = doc_outputs[1]\n",
        "        similarity_scores = self.cos_sim(query_embeddings, doc_embeddings)\n",
        "        return similarity_scores'''\n",
        "\n",
        "# Prepare your dataset\n",
        "train_data = [('What is the capital of France?', 'Paris is the capital of France', 1),\n",
        "              ('Who is the current US President?', 'Joe Biden is the current US President', 1),\n",
        "              ('What is the color of the sky?', 'The sky is blue', 0),\n",
        "              ('How tall is Mount Everest?', 'Mount Everest is 8,848 meters tall', 1)]\n",
        "                # List of tuples (query, document, label)\n",
        "valid_data = [...]  # List of tuples (query, document, label)\n",
        "\n",
        "# Preprocess your data\n",
        "train_query_input_ids = []\n",
        "train_query_attention_mask = []\n",
        "train_doc_input_ids = []\n",
        "train_doc_attention_mask = []\n",
        "train_labels = []\n",
        "'''for query, document, label in train_data:\n",
        "    query_inputs = tokenizer.encode_plus(query, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
        "    doc_inputs = tokenizer.encode_plus(document, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
        "    train_query_input_ids.append(query_inputs['input_ids'])\n",
        "    train_query_attention_mask.append(query_inputs['attention_mask'])\n",
        "    train_doc_input_ids.append(doc_inputs['input_ids'])\n",
        "    train_doc_attention_mask.append(doc_inputs['attention_mask'])\n",
        "    train_labels.append(label)\n",
        "\n",
        "train_query_input_ids = torch.tensor(train_query_input_ids)\n",
        "train_query_attention_mask = torch.tensor(train_query_attention_mask)\n",
        "train_doc_input_ids = torch.tensor(train_doc_input_ids)\n",
        "train_doc_attention_mask = torch.tensor(train_doc_attention_mask)\n",
        "train_labels = torch.tensor(train_labels,dtype=torch.float32,requires_grad=True)'''\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Train the model\n",
        "model = TwoTowerModel()\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    for query, document, label in train_data:\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(query, document)\n",
        "      label = torch.tensor(label,dtype=torch.float32,requires_grad=True)\n",
        "      loss = criterion(outputs.detach(), label.unsqueeze(0))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/sample_data/models/FinetunedFB'\n",
        "torch.save(model.state_dict(), output_path)"
      ],
      "metadata": {
        "id": "v_a6_2-V5C3U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.state_dict().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE7bK9hDEr8J",
        "outputId": "662a4107-597b-4571-fbee-ce85426f60e0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['query_tower.embeddings.position_ids', 'query_tower.embeddings.word_embeddings.weight', 'query_tower.embeddings.position_embeddings.weight', 'query_tower.embeddings.token_type_embeddings.weight', 'query_tower.embeddings.LayerNorm.weight', 'query_tower.embeddings.LayerNorm.bias', 'query_tower.encoder.layer.0.attention.self.query.weight', 'query_tower.encoder.layer.0.attention.self.query.bias', 'query_tower.encoder.layer.0.attention.self.key.weight', 'query_tower.encoder.layer.0.attention.self.key.bias', 'query_tower.encoder.layer.0.attention.self.value.weight', 'query_tower.encoder.layer.0.attention.self.value.bias', 'query_tower.encoder.layer.0.attention.output.dense.weight', 'query_tower.encoder.layer.0.attention.output.dense.bias', 'query_tower.encoder.layer.0.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.0.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.0.intermediate.dense.weight', 'query_tower.encoder.layer.0.intermediate.dense.bias', 'query_tower.encoder.layer.0.output.dense.weight', 'query_tower.encoder.layer.0.output.dense.bias', 'query_tower.encoder.layer.0.output.LayerNorm.weight', 'query_tower.encoder.layer.0.output.LayerNorm.bias', 'query_tower.encoder.layer.1.attention.self.query.weight', 'query_tower.encoder.layer.1.attention.self.query.bias', 'query_tower.encoder.layer.1.attention.self.key.weight', 'query_tower.encoder.layer.1.attention.self.key.bias', 'query_tower.encoder.layer.1.attention.self.value.weight', 'query_tower.encoder.layer.1.attention.self.value.bias', 'query_tower.encoder.layer.1.attention.output.dense.weight', 'query_tower.encoder.layer.1.attention.output.dense.bias', 'query_tower.encoder.layer.1.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.1.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.1.intermediate.dense.weight', 'query_tower.encoder.layer.1.intermediate.dense.bias', 'query_tower.encoder.layer.1.output.dense.weight', 'query_tower.encoder.layer.1.output.dense.bias', 'query_tower.encoder.layer.1.output.LayerNorm.weight', 'query_tower.encoder.layer.1.output.LayerNorm.bias', 'query_tower.encoder.layer.2.attention.self.query.weight', 'query_tower.encoder.layer.2.attention.self.query.bias', 'query_tower.encoder.layer.2.attention.self.key.weight', 'query_tower.encoder.layer.2.attention.self.key.bias', 'query_tower.encoder.layer.2.attention.self.value.weight', 'query_tower.encoder.layer.2.attention.self.value.bias', 'query_tower.encoder.layer.2.attention.output.dense.weight', 'query_tower.encoder.layer.2.attention.output.dense.bias', 'query_tower.encoder.layer.2.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.2.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.2.intermediate.dense.weight', 'query_tower.encoder.layer.2.intermediate.dense.bias', 'query_tower.encoder.layer.2.output.dense.weight', 'query_tower.encoder.layer.2.output.dense.bias', 'query_tower.encoder.layer.2.output.LayerNorm.weight', 'query_tower.encoder.layer.2.output.LayerNorm.bias', 'query_tower.encoder.layer.3.attention.self.query.weight', 'query_tower.encoder.layer.3.attention.self.query.bias', 'query_tower.encoder.layer.3.attention.self.key.weight', 'query_tower.encoder.layer.3.attention.self.key.bias', 'query_tower.encoder.layer.3.attention.self.value.weight', 'query_tower.encoder.layer.3.attention.self.value.bias', 'query_tower.encoder.layer.3.attention.output.dense.weight', 'query_tower.encoder.layer.3.attention.output.dense.bias', 'query_tower.encoder.layer.3.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.3.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.3.intermediate.dense.weight', 'query_tower.encoder.layer.3.intermediate.dense.bias', 'query_tower.encoder.layer.3.output.dense.weight', 'query_tower.encoder.layer.3.output.dense.bias', 'query_tower.encoder.layer.3.output.LayerNorm.weight', 'query_tower.encoder.layer.3.output.LayerNorm.bias', 'query_tower.encoder.layer.4.attention.self.query.weight', 'query_tower.encoder.layer.4.attention.self.query.bias', 'query_tower.encoder.layer.4.attention.self.key.weight', 'query_tower.encoder.layer.4.attention.self.key.bias', 'query_tower.encoder.layer.4.attention.self.value.weight', 'query_tower.encoder.layer.4.attention.self.value.bias', 'query_tower.encoder.layer.4.attention.output.dense.weight', 'query_tower.encoder.layer.4.attention.output.dense.bias', 'query_tower.encoder.layer.4.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.4.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.4.intermediate.dense.weight', 'query_tower.encoder.layer.4.intermediate.dense.bias', 'query_tower.encoder.layer.4.output.dense.weight', 'query_tower.encoder.layer.4.output.dense.bias', 'query_tower.encoder.layer.4.output.LayerNorm.weight', 'query_tower.encoder.layer.4.output.LayerNorm.bias', 'query_tower.encoder.layer.5.attention.self.query.weight', 'query_tower.encoder.layer.5.attention.self.query.bias', 'query_tower.encoder.layer.5.attention.self.key.weight', 'query_tower.encoder.layer.5.attention.self.key.bias', 'query_tower.encoder.layer.5.attention.self.value.weight', 'query_tower.encoder.layer.5.attention.self.value.bias', 'query_tower.encoder.layer.5.attention.output.dense.weight', 'query_tower.encoder.layer.5.attention.output.dense.bias', 'query_tower.encoder.layer.5.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.5.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.5.intermediate.dense.weight', 'query_tower.encoder.layer.5.intermediate.dense.bias', 'query_tower.encoder.layer.5.output.dense.weight', 'query_tower.encoder.layer.5.output.dense.bias', 'query_tower.encoder.layer.5.output.LayerNorm.weight', 'query_tower.encoder.layer.5.output.LayerNorm.bias', 'query_tower.encoder.layer.6.attention.self.query.weight', 'query_tower.encoder.layer.6.attention.self.query.bias', 'query_tower.encoder.layer.6.attention.self.key.weight', 'query_tower.encoder.layer.6.attention.self.key.bias', 'query_tower.encoder.layer.6.attention.self.value.weight', 'query_tower.encoder.layer.6.attention.self.value.bias', 'query_tower.encoder.layer.6.attention.output.dense.weight', 'query_tower.encoder.layer.6.attention.output.dense.bias', 'query_tower.encoder.layer.6.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.6.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.6.intermediate.dense.weight', 'query_tower.encoder.layer.6.intermediate.dense.bias', 'query_tower.encoder.layer.6.output.dense.weight', 'query_tower.encoder.layer.6.output.dense.bias', 'query_tower.encoder.layer.6.output.LayerNorm.weight', 'query_tower.encoder.layer.6.output.LayerNorm.bias', 'query_tower.encoder.layer.7.attention.self.query.weight', 'query_tower.encoder.layer.7.attention.self.query.bias', 'query_tower.encoder.layer.7.attention.self.key.weight', 'query_tower.encoder.layer.7.attention.self.key.bias', 'query_tower.encoder.layer.7.attention.self.value.weight', 'query_tower.encoder.layer.7.attention.self.value.bias', 'query_tower.encoder.layer.7.attention.output.dense.weight', 'query_tower.encoder.layer.7.attention.output.dense.bias', 'query_tower.encoder.layer.7.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.7.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.7.intermediate.dense.weight', 'query_tower.encoder.layer.7.intermediate.dense.bias', 'query_tower.encoder.layer.7.output.dense.weight', 'query_tower.encoder.layer.7.output.dense.bias', 'query_tower.encoder.layer.7.output.LayerNorm.weight', 'query_tower.encoder.layer.7.output.LayerNorm.bias', 'query_tower.encoder.layer.8.attention.self.query.weight', 'query_tower.encoder.layer.8.attention.self.query.bias', 'query_tower.encoder.layer.8.attention.self.key.weight', 'query_tower.encoder.layer.8.attention.self.key.bias', 'query_tower.encoder.layer.8.attention.self.value.weight', 'query_tower.encoder.layer.8.attention.self.value.bias', 'query_tower.encoder.layer.8.attention.output.dense.weight', 'query_tower.encoder.layer.8.attention.output.dense.bias', 'query_tower.encoder.layer.8.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.8.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.8.intermediate.dense.weight', 'query_tower.encoder.layer.8.intermediate.dense.bias', 'query_tower.encoder.layer.8.output.dense.weight', 'query_tower.encoder.layer.8.output.dense.bias', 'query_tower.encoder.layer.8.output.LayerNorm.weight', 'query_tower.encoder.layer.8.output.LayerNorm.bias', 'query_tower.encoder.layer.9.attention.self.query.weight', 'query_tower.encoder.layer.9.attention.self.query.bias', 'query_tower.encoder.layer.9.attention.self.key.weight', 'query_tower.encoder.layer.9.attention.self.key.bias', 'query_tower.encoder.layer.9.attention.self.value.weight', 'query_tower.encoder.layer.9.attention.self.value.bias', 'query_tower.encoder.layer.9.attention.output.dense.weight', 'query_tower.encoder.layer.9.attention.output.dense.bias', 'query_tower.encoder.layer.9.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.9.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.9.intermediate.dense.weight', 'query_tower.encoder.layer.9.intermediate.dense.bias', 'query_tower.encoder.layer.9.output.dense.weight', 'query_tower.encoder.layer.9.output.dense.bias', 'query_tower.encoder.layer.9.output.LayerNorm.weight', 'query_tower.encoder.layer.9.output.LayerNorm.bias', 'query_tower.encoder.layer.10.attention.self.query.weight', 'query_tower.encoder.layer.10.attention.self.query.bias', 'query_tower.encoder.layer.10.attention.self.key.weight', 'query_tower.encoder.layer.10.attention.self.key.bias', 'query_tower.encoder.layer.10.attention.self.value.weight', 'query_tower.encoder.layer.10.attention.self.value.bias', 'query_tower.encoder.layer.10.attention.output.dense.weight', 'query_tower.encoder.layer.10.attention.output.dense.bias', 'query_tower.encoder.layer.10.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.10.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.10.intermediate.dense.weight', 'query_tower.encoder.layer.10.intermediate.dense.bias', 'query_tower.encoder.layer.10.output.dense.weight', 'query_tower.encoder.layer.10.output.dense.bias', 'query_tower.encoder.layer.10.output.LayerNorm.weight', 'query_tower.encoder.layer.10.output.LayerNorm.bias', 'query_tower.encoder.layer.11.attention.self.query.weight', 'query_tower.encoder.layer.11.attention.self.query.bias', 'query_tower.encoder.layer.11.attention.self.key.weight', 'query_tower.encoder.layer.11.attention.self.key.bias', 'query_tower.encoder.layer.11.attention.self.value.weight', 'query_tower.encoder.layer.11.attention.self.value.bias', 'query_tower.encoder.layer.11.attention.output.dense.weight', 'query_tower.encoder.layer.11.attention.output.dense.bias', 'query_tower.encoder.layer.11.attention.output.LayerNorm.weight', 'query_tower.encoder.layer.11.attention.output.LayerNorm.bias', 'query_tower.encoder.layer.11.intermediate.dense.weight', 'query_tower.encoder.layer.11.intermediate.dense.bias', 'query_tower.encoder.layer.11.output.dense.weight', 'query_tower.encoder.layer.11.output.dense.bias', 'query_tower.encoder.layer.11.output.LayerNorm.weight', 'query_tower.encoder.layer.11.output.LayerNorm.bias', 'query_tower.pooler.dense.weight', 'query_tower.pooler.dense.bias', 'doc_tower.embeddings.position_ids', 'doc_tower.embeddings.word_embeddings.weight', 'doc_tower.embeddings.position_embeddings.weight', 'doc_tower.embeddings.token_type_embeddings.weight', 'doc_tower.embeddings.LayerNorm.weight', 'doc_tower.embeddings.LayerNorm.bias', 'doc_tower.encoder.layer.0.attention.self.query.weight', 'doc_tower.encoder.layer.0.attention.self.query.bias', 'doc_tower.encoder.layer.0.attention.self.key.weight', 'doc_tower.encoder.layer.0.attention.self.key.bias', 'doc_tower.encoder.layer.0.attention.self.value.weight', 'doc_tower.encoder.layer.0.attention.self.value.bias', 'doc_tower.encoder.layer.0.attention.output.dense.weight', 'doc_tower.encoder.layer.0.attention.output.dense.bias', 'doc_tower.encoder.layer.0.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.0.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.0.intermediate.dense.weight', 'doc_tower.encoder.layer.0.intermediate.dense.bias', 'doc_tower.encoder.layer.0.output.dense.weight', 'doc_tower.encoder.layer.0.output.dense.bias', 'doc_tower.encoder.layer.0.output.LayerNorm.weight', 'doc_tower.encoder.layer.0.output.LayerNorm.bias', 'doc_tower.encoder.layer.1.attention.self.query.weight', 'doc_tower.encoder.layer.1.attention.self.query.bias', 'doc_tower.encoder.layer.1.attention.self.key.weight', 'doc_tower.encoder.layer.1.attention.self.key.bias', 'doc_tower.encoder.layer.1.attention.self.value.weight', 'doc_tower.encoder.layer.1.attention.self.value.bias', 'doc_tower.encoder.layer.1.attention.output.dense.weight', 'doc_tower.encoder.layer.1.attention.output.dense.bias', 'doc_tower.encoder.layer.1.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.1.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.1.intermediate.dense.weight', 'doc_tower.encoder.layer.1.intermediate.dense.bias', 'doc_tower.encoder.layer.1.output.dense.weight', 'doc_tower.encoder.layer.1.output.dense.bias', 'doc_tower.encoder.layer.1.output.LayerNorm.weight', 'doc_tower.encoder.layer.1.output.LayerNorm.bias', 'doc_tower.encoder.layer.2.attention.self.query.weight', 'doc_tower.encoder.layer.2.attention.self.query.bias', 'doc_tower.encoder.layer.2.attention.self.key.weight', 'doc_tower.encoder.layer.2.attention.self.key.bias', 'doc_tower.encoder.layer.2.attention.self.value.weight', 'doc_tower.encoder.layer.2.attention.self.value.bias', 'doc_tower.encoder.layer.2.attention.output.dense.weight', 'doc_tower.encoder.layer.2.attention.output.dense.bias', 'doc_tower.encoder.layer.2.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.2.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.2.intermediate.dense.weight', 'doc_tower.encoder.layer.2.intermediate.dense.bias', 'doc_tower.encoder.layer.2.output.dense.weight', 'doc_tower.encoder.layer.2.output.dense.bias', 'doc_tower.encoder.layer.2.output.LayerNorm.weight', 'doc_tower.encoder.layer.2.output.LayerNorm.bias', 'doc_tower.encoder.layer.3.attention.self.query.weight', 'doc_tower.encoder.layer.3.attention.self.query.bias', 'doc_tower.encoder.layer.3.attention.self.key.weight', 'doc_tower.encoder.layer.3.attention.self.key.bias', 'doc_tower.encoder.layer.3.attention.self.value.weight', 'doc_tower.encoder.layer.3.attention.self.value.bias', 'doc_tower.encoder.layer.3.attention.output.dense.weight', 'doc_tower.encoder.layer.3.attention.output.dense.bias', 'doc_tower.encoder.layer.3.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.3.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.3.intermediate.dense.weight', 'doc_tower.encoder.layer.3.intermediate.dense.bias', 'doc_tower.encoder.layer.3.output.dense.weight', 'doc_tower.encoder.layer.3.output.dense.bias', 'doc_tower.encoder.layer.3.output.LayerNorm.weight', 'doc_tower.encoder.layer.3.output.LayerNorm.bias', 'doc_tower.encoder.layer.4.attention.self.query.weight', 'doc_tower.encoder.layer.4.attention.self.query.bias', 'doc_tower.encoder.layer.4.attention.self.key.weight', 'doc_tower.encoder.layer.4.attention.self.key.bias', 'doc_tower.encoder.layer.4.attention.self.value.weight', 'doc_tower.encoder.layer.4.attention.self.value.bias', 'doc_tower.encoder.layer.4.attention.output.dense.weight', 'doc_tower.encoder.layer.4.attention.output.dense.bias', 'doc_tower.encoder.layer.4.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.4.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.4.intermediate.dense.weight', 'doc_tower.encoder.layer.4.intermediate.dense.bias', 'doc_tower.encoder.layer.4.output.dense.weight', 'doc_tower.encoder.layer.4.output.dense.bias', 'doc_tower.encoder.layer.4.output.LayerNorm.weight', 'doc_tower.encoder.layer.4.output.LayerNorm.bias', 'doc_tower.encoder.layer.5.attention.self.query.weight', 'doc_tower.encoder.layer.5.attention.self.query.bias', 'doc_tower.encoder.layer.5.attention.self.key.weight', 'doc_tower.encoder.layer.5.attention.self.key.bias', 'doc_tower.encoder.layer.5.attention.self.value.weight', 'doc_tower.encoder.layer.5.attention.self.value.bias', 'doc_tower.encoder.layer.5.attention.output.dense.weight', 'doc_tower.encoder.layer.5.attention.output.dense.bias', 'doc_tower.encoder.layer.5.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.5.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.5.intermediate.dense.weight', 'doc_tower.encoder.layer.5.intermediate.dense.bias', 'doc_tower.encoder.layer.5.output.dense.weight', 'doc_tower.encoder.layer.5.output.dense.bias', 'doc_tower.encoder.layer.5.output.LayerNorm.weight', 'doc_tower.encoder.layer.5.output.LayerNorm.bias', 'doc_tower.encoder.layer.6.attention.self.query.weight', 'doc_tower.encoder.layer.6.attention.self.query.bias', 'doc_tower.encoder.layer.6.attention.self.key.weight', 'doc_tower.encoder.layer.6.attention.self.key.bias', 'doc_tower.encoder.layer.6.attention.self.value.weight', 'doc_tower.encoder.layer.6.attention.self.value.bias', 'doc_tower.encoder.layer.6.attention.output.dense.weight', 'doc_tower.encoder.layer.6.attention.output.dense.bias', 'doc_tower.encoder.layer.6.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.6.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.6.intermediate.dense.weight', 'doc_tower.encoder.layer.6.intermediate.dense.bias', 'doc_tower.encoder.layer.6.output.dense.weight', 'doc_tower.encoder.layer.6.output.dense.bias', 'doc_tower.encoder.layer.6.output.LayerNorm.weight', 'doc_tower.encoder.layer.6.output.LayerNorm.bias', 'doc_tower.encoder.layer.7.attention.self.query.weight', 'doc_tower.encoder.layer.7.attention.self.query.bias', 'doc_tower.encoder.layer.7.attention.self.key.weight', 'doc_tower.encoder.layer.7.attention.self.key.bias', 'doc_tower.encoder.layer.7.attention.self.value.weight', 'doc_tower.encoder.layer.7.attention.self.value.bias', 'doc_tower.encoder.layer.7.attention.output.dense.weight', 'doc_tower.encoder.layer.7.attention.output.dense.bias', 'doc_tower.encoder.layer.7.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.7.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.7.intermediate.dense.weight', 'doc_tower.encoder.layer.7.intermediate.dense.bias', 'doc_tower.encoder.layer.7.output.dense.weight', 'doc_tower.encoder.layer.7.output.dense.bias', 'doc_tower.encoder.layer.7.output.LayerNorm.weight', 'doc_tower.encoder.layer.7.output.LayerNorm.bias', 'doc_tower.encoder.layer.8.attention.self.query.weight', 'doc_tower.encoder.layer.8.attention.self.query.bias', 'doc_tower.encoder.layer.8.attention.self.key.weight', 'doc_tower.encoder.layer.8.attention.self.key.bias', 'doc_tower.encoder.layer.8.attention.self.value.weight', 'doc_tower.encoder.layer.8.attention.self.value.bias', 'doc_tower.encoder.layer.8.attention.output.dense.weight', 'doc_tower.encoder.layer.8.attention.output.dense.bias', 'doc_tower.encoder.layer.8.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.8.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.8.intermediate.dense.weight', 'doc_tower.encoder.layer.8.intermediate.dense.bias', 'doc_tower.encoder.layer.8.output.dense.weight', 'doc_tower.encoder.layer.8.output.dense.bias', 'doc_tower.encoder.layer.8.output.LayerNorm.weight', 'doc_tower.encoder.layer.8.output.LayerNorm.bias', 'doc_tower.encoder.layer.9.attention.self.query.weight', 'doc_tower.encoder.layer.9.attention.self.query.bias', 'doc_tower.encoder.layer.9.attention.self.key.weight', 'doc_tower.encoder.layer.9.attention.self.key.bias', 'doc_tower.encoder.layer.9.attention.self.value.weight', 'doc_tower.encoder.layer.9.attention.self.value.bias', 'doc_tower.encoder.layer.9.attention.output.dense.weight', 'doc_tower.encoder.layer.9.attention.output.dense.bias', 'doc_tower.encoder.layer.9.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.9.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.9.intermediate.dense.weight', 'doc_tower.encoder.layer.9.intermediate.dense.bias', 'doc_tower.encoder.layer.9.output.dense.weight', 'doc_tower.encoder.layer.9.output.dense.bias', 'doc_tower.encoder.layer.9.output.LayerNorm.weight', 'doc_tower.encoder.layer.9.output.LayerNorm.bias', 'doc_tower.encoder.layer.10.attention.self.query.weight', 'doc_tower.encoder.layer.10.attention.self.query.bias', 'doc_tower.encoder.layer.10.attention.self.key.weight', 'doc_tower.encoder.layer.10.attention.self.key.bias', 'doc_tower.encoder.layer.10.attention.self.value.weight', 'doc_tower.encoder.layer.10.attention.self.value.bias', 'doc_tower.encoder.layer.10.attention.output.dense.weight', 'doc_tower.encoder.layer.10.attention.output.dense.bias', 'doc_tower.encoder.layer.10.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.10.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.10.intermediate.dense.weight', 'doc_tower.encoder.layer.10.intermediate.dense.bias', 'doc_tower.encoder.layer.10.output.dense.weight', 'doc_tower.encoder.layer.10.output.dense.bias', 'doc_tower.encoder.layer.10.output.LayerNorm.weight', 'doc_tower.encoder.layer.10.output.LayerNorm.bias', 'doc_tower.encoder.layer.11.attention.self.query.weight', 'doc_tower.encoder.layer.11.attention.self.query.bias', 'doc_tower.encoder.layer.11.attention.self.key.weight', 'doc_tower.encoder.layer.11.attention.self.key.bias', 'doc_tower.encoder.layer.11.attention.self.value.weight', 'doc_tower.encoder.layer.11.attention.self.value.bias', 'doc_tower.encoder.layer.11.attention.output.dense.weight', 'doc_tower.encoder.layer.11.attention.output.dense.bias', 'doc_tower.encoder.layer.11.attention.output.LayerNorm.weight', 'doc_tower.encoder.layer.11.attention.output.LayerNorm.bias', 'doc_tower.encoder.layer.11.intermediate.dense.weight', 'doc_tower.encoder.layer.11.intermediate.dense.bias', 'doc_tower.encoder.layer.11.output.dense.weight', 'doc_tower.encoder.layer.11.output.dense.bias', 'doc_tower.encoder.layer.11.output.LayerNorm.weight', 'doc_tower.encoder.layer.11.output.LayerNorm.bias', 'doc_tower.pooler.dense.weight', 'doc_tower.pooler.dense.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''model_path = '/content/sample_data/models/FinetunedFB'\n",
        "model = TwoTowerModel()\n",
        "state_dic=torch.load(model_path)\n",
        "#state_dict = {key.replace(\"query_tower\", \"query_tower.query_tower\"): value for key, value in state_dic.items()}\n",
        "\n",
        "model.load_state_dict(state_dict)'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "B2tdJ89x5bqb",
        "outputId": "23e1c572-ca29-49ad-e3ed-dbfd9a4ad891"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_path = \\'/content/sample_data/models/FinetunedFB\\'\\nmodel = TwoTowerModel()\\nstate_dic=torch.load(model_path)\\n#state_dict = {key.replace(\"query_tower\", \"query_tower.query_tower\"): value for key, value in state_dic.items()}\\n\\nmodel.load_state_dict(state_dict)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings = []\n",
        "documents=['Paris is the capital of France','joe Biden is the current US President','The sky is blue']\n",
        "for document in documents:\n",
        "    embedding = model.encode_document(document)\n",
        "    document_embeddings.append(embedding)\n"
      ],
      "metadata": {
        "id": "CRadiw_1KotV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "#Building Annoy Index\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "import numpy\n",
        "# Build the index\n",
        "annoy_index = AnnoyIndex(768, metric='euclidean')\n",
        "\n",
        "# Add the document embeddings to the index\n",
        "for i, embedding in enumerate(document_embeddings):\n",
        "    embedding = embedding.numpy().ravel()\n",
        "    annoy_index.add_item(i, embedding)\n",
        "\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "tYPSDh7TKow3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#annoy_index.save('/content/sample_data/models/Sample.ann')"
      ],
      "metadata": {
        "id": "ge_jozalNlGv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = model.encode_query(\"Who is the current US President?\")\n",
        "query_embedding = query_embedding .numpy().ravel()\n",
        "ids, distances = annoy_index.get_nns_by_vector(query_embedding,  1 , include_distances=True)"
      ],
      "metadata": {
        "id": "F1nAKFx1N85l"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwmkT6vUONRA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids, distances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWeDUAEBOL-j",
        "outputId": "d463694a-9105-47ef-92f1-99f163c7e1d4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([], [])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_documents(query, model, tokenizer, device, annoy_index, num_results=5):\n",
        "    query_embedding = model.encode_query(query, model, tokenizer, device)\n",
        "    ids, distances = annoy_index.get_nns_by_vector(query_embedding, num_results, include_distances=True)\n",
        "    return ids, distances"
      ],
      "metadata": {
        "id": "cmkk6X8BMpem"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data = [('What is the capital of France?', 'Paris is the capital of France', 1),\n",
        "              ('Who is the current US President?', 'Joe Biden is the current US President', 1),\n",
        "              ('What is the color of the sky?', 'The sky is blue', 0),\n",
        "              ('How tall is Mount Everest?', 'Mount Everest is 8,848 meters tall', 1)]"
      ],
      "metadata": {
        "id": "oZ8DesvTqfvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./Fine_tuned_FinBERT')\n",
        "tokenizer.save_pretrained('./Tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "bunbIu3vRL5b",
        "outputId": "ab526e06-f50e-4a3f-c714-27a299f0b13d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a1eeee9339c5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Fine_tuned_FinBERT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Tokenizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TwoTowerModel' object has no attribute 'save_pretrained'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data=[('What is the capital of France?', 'Paris is the capital of France', 1),\n",
        "              ('Who is the current US President?', 'Joe Biden is the current US President', 1),\n",
        "              ('What is the color of the sky?', 'The sky is blue', 0),\n",
        "              ('How tall is Mount Everest?', 'Mount Everest is 8,848 meters tall', 1)]\n",
        "'''# Evaluate the model\n",
        "valid_query_input_ids = []\n",
        "valid_query_attention_mask = []\n",
        "valid_doc_input_ids = []\n",
        "valid_doc_attention_mask = []\n",
        "valid_labels = []\n",
        "for query, document, label in valid_data:\n",
        "    query_inputs = tokenizer.encode_plus(query, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
        "    doc_inputs = tokenizer.encode_plus(document, add_special_tokens=True, max_length=512, padding='max_length', truncation=True)\n",
        "    valid_query_input_ids.append(query_inputs['input_ids'])\n",
        "    valid_query_attention_mask.append(query_inputs['attention_mask'])\n",
        "    valid_doc_input_ids.append(doc_inputs['input_ids'])\n",
        "    valid_doc_attention_mask.append(doc_inputs['attention_mask'])\n",
        "    valid_labels.append(label)\n",
        "\n",
        "valid_query_input_ids = torch.tensor(valid_query_input_ids)\n",
        "valid_query_attention_mask = torch.tensor(valid_query_attention_mask)\n",
        "valid_doc_input_ids = torch.tensor(valid_doc_input_ids)\n",
        "valid_doc_attention_mask = torch.tensor(valid_doc_attention_mask)\n",
        "valid_labels = torch.tensor(valid_labels)'''\n",
        "\n",
        "model.eval()\n",
        "for query, document, label in train_data:\n",
        "  with torch.no_grad():\n",
        "      outputs = model(query, document)\n",
        "      prediction = (torch.sigmoid(outputs) > 0.5).long()\n",
        "      #accuracy = (predictions == valid_labels).float().mean().item()\n",
        "      accuracy = (predictions == label).float()\n",
        "      print(accuracy)\n",
        "      print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "aBCHtFcYqN61",
        "outputId": "a8259cd2-2ec6-48ad-9224-759eaf02f063"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-102ad0f235cc>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "me6nlwRbRe1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-DOwaoK7mBD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vn4PtgJfmBGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jL1fLX_dmBH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Sample data\n",
        "data = [\n",
        "    {\n",
        "        \"query\": \"What is the capital of France?\",\n",
        "        \"document\": \"Paris is the capital of France. It is a beautiful city with many attractions.\",\n",
        "        \"answer\": \"Paris\",\n",
        "        \"label\": 1\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is the tallest mountain in the world?\",\n",
        "        \"document\": \"Mount Everest is the tallest mountain in the world. It is located in the Himalayas.\",\n",
        "        \"answer\": \"Mount Everest\",\n",
        "        \"label\": 1\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Who wrote the Harry Potter books?\",\n",
        "        \"document\": \"J.K. Rowling wrote the Harry Potter books. They are a series of fantasy novels.\",\n",
        "        \"answer\": \"J.K. Rowling\",\n",
        "        \"label\": 0\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is the largest country in the world?\",\n",
        "        \"document\": \"Russia is the largest country in the world. It spans across 11 time zones.\",\n",
        "        \"answer\": \"Russia\",\n",
        "        \"label\": 1\n",
        "    }\n",
        "]\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "train_data = data[:2]\n",
        "val_data = data[2:3]\n",
        "test_data = data[3:]\n",
        "\n",
        "# Custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query = self.data[idx][\"query\"]\n",
        "        document = self.data[idx][\"document\"]\n",
        "        answer = self.data[idx][\"answer\"]\n",
        "        label = self.data[idx][\"label\"]\n",
        "        return query, document, answer, label\n",
        "\n",
        "# Dataloader for training\n",
        "train_dataset = CustomDataset(train_data)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (queries, documents, answers, labels) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        query_embeddings = query_tower(queries)\n",
        "        document_embeddings = document_tower(documents)\n",
        "        inputs = torch.cat((query_embeddings, document_embeddings), dim=1)\n",
        "        outputs = final_layer(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "IJrXFZRNmBKc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}